{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Probe Experiments\n",
    "A first try at generating data in a procgen maze environment, and using that to construct a linear probe to detect a \"cheese signal\" in the neural network layers of a pre-trained RL agent. \n",
    "\n",
    "## Initialize Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from procgen import ProcgenGym3Env\n",
    "from procgen_tools import maze\n",
    "from procgen_tools.models import load_policy\n",
    "from procgen_tools import maze as maze_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "save_dir = Path(\"maze_linear_probe_data\")\n",
    "if not save_dir.is_dir():\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gym environment will be created through `procgen-tools`. It provides a wrapper around the original procgen environment to make it compatible with gym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prev_level_seed', 'prev_level_complete', 'level_seed', 'rgb'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "wrapped_venv = maze_api.create_venv(\n",
    "    num=1, start_level=int(seed), num_levels=0, num_threads = 4\n",
    ")\n",
    "wrapped_venv.env.get_info()[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CEnv lib_path=/Users/bensturgeon/Library/Caches/pypoetry/virtualenvs/ai-safety-camp-Y8XZewIj-py3.10/lib/python3.10/site-packages/procgen/data/prebuilt/libenv.dylib options={'center_agent': True, 'use_generated_assets': False, 'use_monochrome_assets': False, 'restrict_themes': False, 'use_backgrounds': True, 'paint_vel_info': False, 'distribution_mode': 1, 'env_name': 'maze', 'num_levels': 0, 'start_level': 42, 'num_actions': 15, 'use_sequential_levels': False, 'debug_mode': 0, 'rand_seed': 424112009, 'num_threads': 4, 'render_human': True, 'resource_root': '/Users/bensturgeon/Library/Caches/pypoetry/virtualenvs/ai-safety-camp-Y8XZewIj-py3.10/lib/python3.10/site-packages/procgen/data/assets/'}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the procgen env directly like so\n",
    "wrapped_venv.env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Agent\n",
    "Download one of the agents from the [trained model files](https://drive.google.com/drive/folders/1Ig7bzRlieyYFcdKL_PM-guSWR8WryDOL). I used `maze_I/model_rand_region_5` without knowing about the performance of this agent. Do not forget to rename the model file or change the filename below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = load_policy('model_rand_region_15.pth', action_size=15, device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_episode(model, maze_environment,logger, argmax=True, max_time_steps=256):\n",
    "    model.eval()  # Switch off gradient tracking and other training time mechanisms\n",
    "    obs = maze_environment.reset()\n",
    "    logger.update_environment(maze_environment) \n",
    "    for step in range(max_time_steps):\n",
    "        out, _ = model(torch.FloatTensor(obs))\n",
    "        act = out.probs.argmax(dim=-1).numpy() if argmax else out.sample().numpy()\n",
    "        obs, rew, done, info = maze_environment.step(act)\n",
    "        logger.log(model, step, act, obs, rew, done)  # Updated call\n",
    "        if done:\n",
    "            logger.done()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Model Activations\n",
    "Activations can be [logged with `circrl`](https://github.com/montemac/circrl/tree/main). The hook manager logs a single activation by default. Since we want to have activations spread over the entire eposide we will use a custom hook manager that can be reset between episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_layer_names(model):\n",
    "    return [name for name, module in model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'embedder', 'embedder.block1', 'embedder.block1.conv', 'embedder.block1.maxpool', 'embedder.block1.res1', 'embedder.block1.res1.relu1', 'embedder.block1.res1.conv1', 'embedder.block1.res1.relu2', 'embedder.block1.res1.conv2', 'embedder.block1.res1.resadd', 'embedder.block1.res2', 'embedder.block1.res2.relu1', 'embedder.block1.res2.conv1', 'embedder.block1.res2.relu2', 'embedder.block1.res2.conv2', 'embedder.block1.res2.resadd', 'embedder.block2', 'embedder.block2.conv', 'embedder.block2.maxpool']\n"
     ]
    }
   ],
   "source": [
    "names = get_model_layer_names(policy)\n",
    "print(names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        print(output)\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Attach the hook to a specific layer, e.g., model.layer1\n",
    "policy.register_forward_hook(get_activation('embedder.block1.conv'))\n",
    "\n",
    "# Run your data through the model\n",
    "observation = torch.tensor(observations[0], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "\n",
    "output = policy(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a hook to log the activations of the corresponding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before logging\n",
      "dict_keys([])\n",
      "After logging\n",
      "(Categorical(logits: torch.Size([1, 15])), tensor([8.0210], grad_fn=<ViewBackward0>))\n",
      "dict_keys(['embedder.block1.conv', 'embedder.block1', 'embedder'])\n"
     ]
    }
   ],
   "source": [
    "from circrl import hooks\n",
    "\n",
    "policy_hook = hooks.HookManager(\n",
    "    model=policy,\n",
    "    cache=names[1:4]\n",
    ")\n",
    "\n",
    "print(\"Before logging\")\n",
    "print(policy_hook.cache_results.keys())\n",
    "\n",
    "# Run an environment update in the policy hook context to start logging\n",
    "with policy_hook:\n",
    "    obs = wrapped_venv.reset()\n",
    "    output = policy(torch.FloatTensor(obs))\n",
    "\n",
    "print(\"After logging\")\n",
    "print(output)\n",
    "print(policy_hook.cache_results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful! In the default log setting the `cache_results` gets overwritten every time the policy is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log size after a single execution:\n",
      "\ttorch.Size([1, 256])\n",
      "Log size after a multiple executions:\n",
      "\ttorch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "with policy_hook:\n",
    "    obs = wrapped_venv.reset()\n",
    "    output = policy(torch.FloatTensor(obs))\n",
    "\n",
    "print(\"log size after a single execution:\")\n",
    "print(f\"\\t{policy_hook.cache_results[names[1]].size()}\")\n",
    "\n",
    "with policy_hook:    \n",
    "    obs = wrapped_venv.reset()\n",
    "    for _ in range(10):\n",
    "        output = policy(torch.FloatTensor(obs))\n",
    "\n",
    "print(\"Log size after a multiple executions:\")\n",
    "print(f\"\\t{policy_hook.cache_results[names[1]].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Training Data\n",
    "To gather training data we need to run multiple episodes and store the activations of the model alongside the environment parameters. Procgen-tools provides some convenience functions to make this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_maze_training_data(model, n_episodes,logger, on_episode_step, on_episode_done ):\n",
    "    max_seed = int(1e9)\n",
    "    seeds = np.random.default_rng().choice(max_seed, size=n_episodes, replace=False)\n",
    "\n",
    "    for seed in tqdm(seeds):\n",
    "        wrapped_venv = maze_api.create_venv(\n",
    "            num=1, start_level=int(seed), num_levels=0, num_threads = 4\n",
    "        )  # Convenience functions\n",
    "        \n",
    "        run_episode(model, wrapped_venv,logger)\n",
    "    logger.reset_episode_counter()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a system to log activations and environment variables persistently. It would be best to avoid having to edit code related to model execution when logging to avoid introducting bugs. We can use something like the following logging setup to log episodic data to disk at the end of every episode. It combines the previous logging function with hooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class ProbeDataLogger:\n",
    "    def __init__(self, model, save_file_path=\"\"):\n",
    "        self._init_logs()\n",
    "\n",
    "        self.model = model\n",
    "        layer_names = get_model_layer_names(model)\n",
    "        self.model_hook = hooks.HookManager(\n",
    "            model=model,\n",
    "            cache=names\n",
    "        )\n",
    "        save_file_path = Path(save_file_path)\n",
    "        self._file_path = save_file_path\n",
    "        self._file_extension = \".pkl\"\n",
    "        self._current_ep = 0\n",
    "        self.env = None\n",
    "    \n",
    "    \n",
    "    def reset_episode_counter(self):\n",
    "        \"\"\"Reset the episode counter to 0.\"\"\"\n",
    "        self._current_ep = 0\n",
    "    def update_environment(self, env):\n",
    "        \"\"\"Update the logger to use the current environment instance.\"\"\"\n",
    "        self.env = env\n",
    "\n",
    "    def log(self, model, environment, step, act, obs, rew):\n",
    "        self.observations.append(obs)\n",
    "        self.rewards.append(rew)\n",
    "        self.activations.append(self.model_hook.cache_results)\n",
    "\n",
    "        # Using these functions only works because the environment is wrapped in\n",
    "        # the training data generation method\n",
    "        state = maze_api.state_from_venv(self.env)\n",
    "        grid = maze_api.get_grid(state.state_vals)\n",
    "        self.cheese_positions.append(maze_api.get_cheese_pos(grid))\n",
    "\n",
    "    def done(self):\n",
    "        self._current_ep += 1\n",
    "        self.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        \"\"\"Flush data in log buffer to file and reset buffer\"\"\"\n",
    "        save_path = self._file_path / Path(\"ep_\" + str(self._current_ep) + str(self._file_extension))\n",
    "        print(save_path)\n",
    "        self._save_logs_to_file(save_path)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self._init_logs()\n",
    "\n",
    "    def _save_logs_to_file(self, file_path):\n",
    "        write_mode = 'wb' \n",
    "\n",
    "        obs = torch.tensor(self.observations)\n",
    "        rew = torch.tensor(self.rewards)\n",
    "        cheese_positions = torch.tensor(self.cheese_positions)\n",
    "        \n",
    "        with open(file_path, write_mode) as file:\n",
    "            pickle.dump(self.observations, file)\n",
    "            pickle.dump(self.rewards, file)\n",
    "            pickle.dump(self.activations, file)\n",
    "            pickle.dump(self.cheese_positions, file)\n",
    "\n",
    "    def _init_logs(self):\n",
    "        self.observations = []\n",
    "        self.rewards = []\n",
    "        self.activations = []\n",
    "        self.cheese_positions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load back the data. Including the loading functionality in the logging class might be convenient, but here I will simply recover it manually as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/f16y6j7x0j5d0vv3pvq80c680000gn/T/ipykernel_6392/2808487301.py:51: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  obs = torch.tensor(self.observations)\n",
      "/var/folders/58/f16y6j7x0j5d0vv3pvq80c680000gn/T/ipykernel_6392/2808487301.py:52: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  rew = torch.tensor(self.rewards)\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/ep_1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/ep_2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/ep_3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frames =[]\n",
    "logs = ProbeDataLogger(policy, save_file_path=save_dir)\n",
    "with logs.model_hook:\n",
    "    generate_maze_training_data(policy, 3,logs, logs.log, logs.done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded activations: 20\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_logs(file_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - file_path (str): The path to the pickle file.\n",
    "    \n",
    "    Returns:\n",
    "    - observations (list): Environment observations.\n",
    "    - rewards (list): Environment rewards.\n",
    "    - activations (list): The list of activations unpickled from the file.\n",
    "    - cheese_positions (list): Cheese position tensors in x, y.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Unpickle in the order they were saved: observations, rewards, activations\n",
    "        observations = pickle.load(file)\n",
    "        rewards = pickle.load(file)\n",
    "        activations = pickle.load(file)\n",
    "        cheese_positions = pickle.load(file)\n",
    "    \n",
    "    return observations, rewards, activations, cheese_positions\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = save_dir / 'ep_1.pkl'\n",
    "_, _, activations, _ = load_logs(file_path)\n",
    "print(\"Loaded activations:\", len(activations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training A Linear Probe\n",
    "Training a linear probe requires choosing what layers we are probing, and with respect to what target. That in turn determines the structure of the probe.\n",
    "\n",
    "### Generate Training Data\n",
    "\n",
    "In this case we will probe an early convolutional layer in the network for cheese position signal as an example. First we load a model and generate some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log directory\n",
    "import os\n",
    "\n",
    "log_dir = save_dir / Path(\"logs\")\n",
    "\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and create logger\n",
    "probe_policy = load_policy('model_rand_region_15.pth', action_size=15, device=torch.device('cpu'))\n",
    "logger = ProbeDataLogger(probe_policy, save_file_path=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/var/folders/58/f16y6j7x0j5d0vv3pvq80c680000gn/T/ipykernel_6392/2503070101.py:56: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  rew = torch.tensor(self.rewards)\n",
      "  2%|▏         | 1/50 [00:01<01:14,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_11.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:03<01:29,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_12.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:04<00:34,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_13.pkl\n",
      "maze_linear_probe_data/logs/ep_14.pkl\n",
      "maze_linear_probe_data/logs/ep_15.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:06<00:43,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_16.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:07<00:46,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_17.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:08<00:36,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_18.pkl\n",
      "maze_linear_probe_data/logs/ep_19.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:08<00:25,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_20.pkl\n",
      "maze_linear_probe_data/logs/ep_21.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:09<00:17,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_22.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:17<01:03,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_23.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:18<00:51,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_24.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:27<01:29,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_25.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:39<01:54,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_26.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:43<01:56,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_27.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:45<01:34,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_28.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:46<01:14,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_29.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:47<00:59,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_30.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:48<00:48,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_31.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:50<00:42,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_32.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:50<00:31,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_33.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:51<00:29,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_34.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:52<00:25,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_35.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:53<00:23,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_36.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:53<00:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_37.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:54<00:11,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_38.pkl\n",
      "maze_linear_probe_data/logs/ep_39.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:55<00:10,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_40.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [00:55<00:08,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_41.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:56<00:10,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_42.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:57<00:10,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_43.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [01:07<00:30,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_44.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:09<00:23,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_45.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:09<00:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_46.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [01:21<00:16,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_47.pkl\n",
      "maze_linear_probe_data/logs/ep_48.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [01:21<00:10,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_49.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:23<00:08,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_50.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:24<00:06,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_51.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [01:33<00:05,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_52.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [01:35<00:02,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_53.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:35<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze_linear_probe_data/logs/ep_54.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "with logger.model_hook:\n",
    "    generate_maze_training_data(probe_policy, 50, logger, logger.log, logger.done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probe Training\n",
    "\n",
    "We need to load the episode data, process it into a format suitable for the training process and then train [a linear probe](https://github.com/montemac/circrl/blob/33534f2f78547b38172e3a4f0d682bc8b5b46b4f/src/circrl/probing.py#L47). For this particular version we can process the episodic data into files of numpy arrays or pytorch tensors. We'll choose pytorch tensors here. \n",
    "\n",
    "Alternatively the data could be batched in files to reduce read/write overhead. It might be worth doing if compute bottlenecks become an obvious concern.\n",
    "\n",
    "#### Regression Probe\n",
    "\n",
    "Using the Ridge Regressor provided by SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def fit_linear_probe(model: Ridge, layer_name: str, inputs: np.ndarray, targets: np.ndarray, random_seed: int = 42):\n",
    "    test_size = 0.2\n",
    "    inputs_train, inputs_test, targets_train, targets_test = train_test_split(\n",
    "        inputs, targets, test_size=test_size, random_state=random_seed\n",
    "    )\n",
    "\n",
    "    model.fit(inputs_train, targets_train)\n",
    "    return {\n",
    "        \"train_score\": model.score(inputs_train, targets_train),\n",
    "        \"test_score\": model.score(inputs_test, targets_test),\n",
    "        \"x_train\": inputs_train,\n",
    "        \"y_train\": targets_train,\n",
    "        \"x_test\": inputs_test,\n",
    "        \"y_test\": targets_test,\n",
    "        \"model\": model,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: -1.6420198534206065e-13\n",
      "test score: 0.0\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "mdl = Ridge(random_state=seed)\n",
    "layer_name = \"embedder.block1.conv\"\n",
    "data_path = save_dir / \"logs\" / \"ep_1.pkl\"\n",
    "\n",
    "_, _, layer_activations, cheese_positions = load_logs(data_path)\n",
    "assert layer_name in layer_activations[0].keys(), \"Cannot find layer '{layer_name}' in activations\"\n",
    "\n",
    "inputs = torch.stack([act[layer_name] for act in layer_activations], dim=0)\n",
    "inputs = inputs.detach().numpy()\n",
    "# Explicit choice to use all the activations as input instead of sampling (might need to reduce input feature space significantly to prevent overfitting)\n",
    "inputs = np.reshape(inputs, (inputs.shape[0], -1))\n",
    "\n",
    "targets = torch.tensor(cheese_positions)\n",
    "targets = targets.detach().numpy()\n",
    "\n",
    "results = fit_linear_probe(mdl, layer_name, inputs, targets, seed)\n",
    "print(f\"train score: {results['train_score']}\")\n",
    "print(f\"test score: {results['test_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_probe(model: Ridge, layer_name: str, episode_data_dir: Path, random_seed: int = 42):\n",
    "    all_inputs = []\n",
    "    all_targets = []\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    # Aggregate data from all files first\n",
    "    for data_file in episode_data_dir.glob('*.pkl'):\n",
    "        _, _, layer_activations, cheese_positions = load_logs(data_file)\n",
    "        assert layer_name in layer_activations[0].keys(), \"Cannot find layer '{layer_name}' in activations\"\n",
    "        \n",
    "        in_tmp = torch.stack([act[layer_name] for act in layer_activations], dim=0).detach().numpy()\n",
    "        in_tmp = np.reshape(in_tmp, (in_tmp.shape[0], -1))\n",
    "        tar_tmp = torch.tensor(cheese_positions).detach().numpy()\n",
    "\n",
    "        all_inputs.append(in_tmp)\n",
    "        all_targets.append(tar_tmp)\n",
    "\n",
    "\n",
    "\n",
    "    # Concatenate all collected data\n",
    "    inputs = np.concatenate(all_inputs, axis=0)\n",
    "    targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Now, train the model once with all the data\n",
    "    results = fit_linear_probe(model, layer_name, inputs, targets, random_seed)\n",
    "    train_scores.append(results['train_score'])\n",
    "    test_scores.append(results['test_score'])\n",
    "\n",
    "    # Calculate and print overall performance\n",
    "    mean_train_score = np.mean(train_scores)\n",
    "    mean_test_score = np.mean(test_scores)\n",
    "    unique_targets = np.unique(targets)\n",
    "    print(f\"Mean train score: {mean_train_score}\")\n",
    "    print(f\"Mean test score: {mean_test_score}\")\n",
    "    print(f\"Number of unique targets: {len(unique_targets)}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1383, 1382]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedder.block1.conv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m data_path \u001b[38;5;241m=\u001b[39m save_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_linear_probe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 26\u001b[0m, in \u001b[0;36mtrain_linear_probe\u001b[0;34m(model, layer_name, episode_data_dir, random_seed)\u001b[0m\n\u001b[1;32m     23\u001b[0m targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_targets, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Now, train the model once with all the data\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mfit_linear_probe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m train_scores\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     28\u001b[0m test_scores\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mfit_linear_probe\u001b[0;34m(model, layer_name, inputs, targets, random_seed)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_linear_probe\u001b[39m(model: Ridge, layer_name: \u001b[38;5;28mstr\u001b[39m, inputs: np\u001b[38;5;241m.\u001b[39mndarray, targets: np\u001b[38;5;241m.\u001b[39mndarray, random_seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m):\n\u001b[1;32m      6\u001b[0m     test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     inputs_train, inputs_test, targets_train, targets_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(inputs_train, targets_train)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mscore(inputs_train, targets_train),\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mscore(inputs_test, targets_test),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m     20\u001b[0m     }\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-safety-camp-Y8XZewIj-py3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-safety-camp-Y8XZewIj-py3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2657\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2662\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-safety-camp-Y8XZewIj-py3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:476\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 476\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-safety-camp-Y8XZewIj-py3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    433\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1383, 1382]"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "mdl = Ridge(random_state=seed)\n",
    "layer_name = \"embedder.block1.conv\"\n",
    "data_path = save_dir / \"logs\"\n",
    "\n",
    "model = train_linear_probe(mdl, layer_name, data_path, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
