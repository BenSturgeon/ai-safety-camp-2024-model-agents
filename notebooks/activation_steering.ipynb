{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import heist\n",
    "import helpers\n",
    "import torch.distributions\n",
    "import torch\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from helpers import generate_action, load_model\n",
    "from procgen import ProcgenGym3Env\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from procgen import ProcgenGym3Env\n",
    "import struct\n",
    "import typing\n",
    "from typing import Tuple, Dict, Callable, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from src.policies_modified import ImpalaCNN\n",
    "from procgen_tools.procgen_wrappers import VecExtractDictObs, TransposeFrame, ScaledFloatFrame\n",
    "\n",
    "from gym3 import ToBaselinesVecEnv\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ordered_layer_names = {\n",
    " 0: 'conv_seqs',\n",
    " 1: 'conv_seqs.0',\n",
    " 2: 'conv_seqs.0.conv',\n",
    " 3: 'conv_seqs.0.max_pool2d',\n",
    " 4: 'conv_seqs.0.res_block0',\n",
    " 5: 'conv_seqs.0.res_block0.conv0',\n",
    " 6: 'conv_seqs.0.res_block0.conv1',\n",
    " 7: 'conv_seqs.0.res_block1',\n",
    " 8: 'conv_seqs.0.res_block1.conv0',\n",
    " 9: 'conv_seqs.0.res_block1.conv1',\n",
    " 10: 'conv_seqs.1',\n",
    " 11: 'conv_seqs.1.conv',\n",
    " 12: 'conv_seqs.1.max_pool2d',\n",
    " 13: 'conv_seqs.1.res_block0',\n",
    " 14: 'conv_seqs.1.res_block0.conv0',\n",
    " 15: 'conv_seqs.1.res_block0.conv1',\n",
    " 16: 'conv_seqs.1.res_block1',\n",
    " 17: 'conv_seqs.1.res_block1.conv0',\n",
    " 18: 'conv_seqs.1.res_block1.conv1',\n",
    " 19: 'conv_seqs.2',\n",
    " 20: 'conv_seqs.2.conv',\n",
    " 21: 'conv_seqs.2.max_pool2d',\n",
    " 22: 'conv_seqs.2.res_block0',\n",
    " 23: 'conv_seqs.2.res_block0.conv0',\n",
    " 24: 'conv_seqs.2.res_block0.conv1',\n",
    " 25: 'conv_seqs.2.res_block1',\n",
    " 26: 'conv_seqs.2.res_block1.conv0',\n",
    " 27: 'conv_seqs.2.res_block1.conv1',\n",
    " 28: 'hidden_fc',\n",
    " 29: 'logits_fc',\n",
    " 30: 'value_fc'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_gem_steering_experiment() got an unexpected keyword argument 'filepath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_episodes):\n\u001b[1;32m     67\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_steering_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 68\u001b[0m     total_reward_steering, total_reward \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gem_steering_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodification_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_gif\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m total_reward_steering \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     70\u001b[0m         count_rewards_0 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_gem_steering_experiment() got an unexpected keyword argument 'filepath'"
     ]
    }
   ],
   "source": [
    "def run_gem_steering_experiment(model_path, layer_number, modification_value, num_levels=1, start_level=5, episode_timeout=200, save_gif=False):\n",
    "    start_level = random.randint(1, 10000)\n",
    "    venv = heist.create_venv(num=1, num_levels=num_levels, start_level=start_level)\n",
    "    state = heist.state_from_venv(venv, 0)\n",
    "    unchanged_obs = venv.reset()\n",
    "\n",
    "\n",
    "\n",
    "    unchanged_obs= venv.reset()\n",
    "    state_values = state.state_vals\n",
    "\n",
    "    for ents in state_values[\"ents\"]:\n",
    "        if ents[\"image_type\"].val== 9:\n",
    "            gem_x = ents[\"x\"].val \n",
    "            gem_y = ents[\"y\"].val \n",
    "\n",
    "    state.remove_gem()\n",
    "\n",
    "\n",
    "    state_bytes = state.state_bytes\n",
    "    if state_bytes is not None:\n",
    "        venv.env.callmethod(\"set_state\", [state_bytes])\n",
    "        modified_obs = venv.reset()\n",
    "\n",
    "    state = heist.state_from_venv(venv, 0)\n",
    "\n",
    "    state.set_gem_position(gem_y-.5,gem_x-.5)\n",
    "\n",
    "    state_bytes = state.state_bytes\n",
    "\n",
    "    if state_bytes is not None:\n",
    "        venv.env.callmethod(\"set_state\", [state_bytes])\n",
    "    # Load model and calculate steering vector\n",
    "    model = helpers.load_model(model_path=model_path)\n",
    "    layer_names = helpers.get_model_layer_names(model)\n",
    "    steering_layer_unchanged = ordered_layer_names[layer_number]\n",
    "    steering_layer = helpers.rename_path(steering_layer_unchanged)\n",
    "\n",
    "    model_activations = helpers.ModelActivations(model)\n",
    "    model_activations.clear_hooks()\n",
    "    output1, unmodified_activations = model_activations.run_with_cache(helpers.observation_to_rgb(unchanged_obs), layer_names)\n",
    "    model_activations.clear_hooks()\n",
    "    output2, modified_obs_activations = model_activations.run_with_cache(helpers.observation_to_rgb(modified_obs), layer_names)\n",
    "\n",
    "    steering_vector = unmodified_activations[steering_layer][0] - modified_obs_activations[steering_layer][0]\n",
    "\n",
    "\n",
    "    # Run episode with steering\n",
    "    total_reward_steering, frames_steering, observations_steering = helpers.run_episode_with_steering_and_save_as_gif(\n",
    "        venv, model, steering_vector, steering_layer=ordered_layer_names[layer_number],\n",
    "        modification_value=modification_value, filepath=f'episode_steering_{episode}.gif',\n",
    "        save_gif=save_gif, episode_timeout=episode_timeout\n",
    "    )\n",
    "\n",
    "    return total_reward_steering, total_reward\n",
    "\n",
    "\n",
    "model_path = \"../model_9501.0.pt\"\n",
    "modification_value = -2\n",
    "total_episodes = 20\n",
    "best_layer = None\n",
    "best_score = 0\n",
    "\n",
    "for layer_number in range(1, 30):  # Adjusted range to be between 1 and 29 inclusive\n",
    "    count_rewards_0 = 0\n",
    "    for episode in range(total_episodes):\n",
    "        filepath=f'episode_steering_{episode}.gif'\n",
    "        total_reward_steering, total_reward = run_gem_steering_experiment(model_path, layer_number, modification_value, save_gif=False, filepath=filepath)\n",
    "        if total_reward_steering == 0:\n",
    "            count_rewards_0 += 1\n",
    "    print(f\"Layer {ordered_layer_names[layer_number]}, {layer_number}: Number of times total reward steering was 0: {count_rewards_0}/{total_episodes}\")\n",
    "    if count_rewards_0 > best_score:\n",
    "        best_score = count_rewards_0\n",
    "        best_layer = layer_number\n",
    "\n",
    "print(f\"Best layer: {best_layer} with score: {best_score}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode_with_steering_and_check_target_acquisition(env, model, steering_vector, steering_layer, modification_value,filepath='../gifs/run.gif', save_gif=False, episode_timeout=400, is_procgen_env=True):\n",
    "    observations = []\n",
    "    observation = env.reset()\n",
    "\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    frames=[]\n",
    "    activations = {}\n",
    "    state = heist.state_from_venv(env, 0)\n",
    "\n",
    "    state_vals = state.state_vals\n",
    "\n",
    "    lock_positions_before = heist.get_lock_statuses(state_vals)\n",
    "    print(lock_positions_before)\n",
    "    num_changes_expected = len(lock_positions_before)\n",
    "    num_changes_counted = 0\n",
    "    count = 0\n",
    "    while not done:\n",
    "        \n",
    "        if save_gif:\n",
    "            frames.append(env.render(mode='rgb_array'))\n",
    "            helpers.plot_single_observation(observation)\n",
    "\n",
    "        observation= np.squeeze(observation)\n",
    "        observation =np.transpose(observation, (1,2,0))\n",
    "        converted_obs = helpers.observation_to_rgb(observation)\n",
    "        action = helpers.generate_action_with_steering(model, converted_obs, steering_vector, steering_layer,modification_value, is_procgen_env)\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "    \n",
    "        state = heist.state_from_venv(env, 0)\n",
    "        \n",
    "        # state_bytes = state.state_bytes\n",
    "        \n",
    "        # if not done:\n",
    "        #     state = heist.state_from_venv(env, 0)\n",
    "        #     full_grid = state.full_grid(with_mouse=False)\n",
    "        #     entities = state.state_vals[\"ents\"]\n",
    "        #     legal_positions = heist.get_legal_mouse_positions(full_grid, entities)\n",
    "\n",
    "        state_vals = state.state_vals\n",
    "        lock_positions_after = heist.get_lock_statuses(state_vals)\n",
    "        # print(lock_positions_before, lock_positions_after)\n",
    "        # if lock_positions_before != lock_positions_after:\n",
    "        #     num_changes_counted +=1\n",
    "        # lock_positions_before = lock_positions_after\n",
    "        total_reward += reward\n",
    "        observations.append(converted_obs)\n",
    "        count +=1\n",
    "        if count >= episode_timeout:\n",
    "            break\n",
    "    \n",
    "    if save_gif:\n",
    "        imageio.mimsave(filepath, frames, fps=30)\n",
    "        print(f\"Saved gif to {filepath}\")\n",
    "\n",
    "    # if num_changes_counted == num_changes_expected and total_reward == 0: return True\n",
    "    if total_reward == 0: return True\n",
    "\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': StateValue(val=4.5, idx=13916), 'y': StateValue(val=4.5, idx=13920), 'vx': StateValue(val=0.0, idx=13924), 'vy': StateValue(val=0.0, idx=13928), 'rx': StateValue(val=0.5, idx=13932), 'ry': StateValue(val=0.5, idx=13936), 'type': StateValue(val=1, idx=13940), 'image_type': StateValue(val=1, idx=13944), 'image_theme': StateValue(val=0, idx=13948), 'render_z': StateValue(val=0, idx=13952), 'will_erase': StateValue(val=0, idx=13956), 'collides_with_entities': StateValue(val=0, idx=13960), 'collision_margin': StateValue(val=0.0, idx=13964), 'rotation': StateValue(val=0.0, idx=13968), 'vrot': StateValue(val=0.0, idx=13972), 'is_reflected': StateValue(val=0, idx=13976), 'fire_time': StateValue(val=-1, idx=13980), 'spawn_time': StateValue(val=-1, idx=13984), 'life_time': StateValue(val=0, idx=13988), 'expire_time': StateValue(val=-1, idx=13992), 'use_abs_coords': StateValue(val=0, idx=13996), 'friction': StateValue(val=1.0, idx=14000), 'smart_step': StateValue(val=0, idx=14004), 'avoids_collisions': StateValue(val=0, idx=14008), 'auto_erase': StateValue(val=1, idx=14012), 'alpha': StateValue(val=1.0, idx=14016), 'health': StateValue(val=1.0, idx=14020), 'theta': StateValue(val=-100.0, idx=14024), 'grow_rate': StateValue(val=1.0, idx=14028), 'alpha_decay': StateValue(val=1.0, idx=14032), 'climber_spawn_x': StateValue(val=0.0, idx=14036)}, {'x': StateValue(val=6.5, idx=14040), 'y': StateValue(val=0.5, idx=14044), 'vx': StateValue(val=0.0, idx=14048), 'vy': StateValue(val=0.0, idx=14052), 'rx': StateValue(val=0.5, idx=14056), 'ry': StateValue(val=0.5, idx=14060), 'type': StateValue(val=1, idx=14064), 'image_type': StateValue(val=1, idx=14068), 'image_theme': StateValue(val=1, idx=14072), 'render_z': StateValue(val=0, idx=14076), 'will_erase': StateValue(val=0, idx=14080), 'collides_with_entities': StateValue(val=0, idx=14084), 'collision_margin': StateValue(val=0.0, idx=14088), 'rotation': StateValue(val=0.0, idx=14092), 'vrot': StateValue(val=0.0, idx=14096), 'is_reflected': StateValue(val=0, idx=14100), 'fire_time': StateValue(val=-1, idx=14104), 'spawn_time': StateValue(val=-1, idx=14108), 'life_time': StateValue(val=0, idx=14112), 'expire_time': StateValue(val=-1, idx=14116), 'use_abs_coords': StateValue(val=0, idx=14120), 'friction': StateValue(val=1.0, idx=14124), 'smart_step': StateValue(val=0, idx=14128), 'avoids_collisions': StateValue(val=0, idx=14132), 'auto_erase': StateValue(val=1, idx=14136), 'alpha': StateValue(val=1.0, idx=14140), 'health': StateValue(val=1.0, idx=14144), 'theta': StateValue(val=-100.0, idx=14148), 'grow_rate': StateValue(val=1.0, idx=14152), 'alpha_decay': StateValue(val=1.0, idx=14156), 'climber_spawn_x': StateValue(val=0.0, idx=14160)}]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "unpack requires a buffer of 4 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m output2, modified_obs_activations \u001b[38;5;241m=\u001b[39m model_activations\u001b[38;5;241m.\u001b[39mrun_with_cache(helpers\u001b[38;5;241m.\u001b[39mobservation_to_rgb(modified_obs), layer_names)\n\u001b[1;32m     54\u001b[0m steering_vector \u001b[38;5;241m=\u001b[39m unmodified_activations[steering_layer][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m modified_obs_activations[steering_layer][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 56\u001b[0m \u001b[43mrun_episode_with_steering_and_check_target_acquisition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvenv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteering_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteering_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordered_layer_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_number\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodification_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodification_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode_steering_locks.gif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_gif\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_timeout\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[98], line 41\u001b[0m, in \u001b[0;36mrun_episode_with_steering_and_check_target_acquisition\u001b[0;34m(env, model, steering_vector, steering_layer, modification_value, filepath, save_gif, episode_timeout, is_procgen_env)\u001b[0m\n\u001b[1;32m     31\u001b[0m state \u001b[38;5;241m=\u001b[39m heist\u001b[38;5;241m.\u001b[39mstate_from_venv(env, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# state_bytes = state.state_bytes\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# if not done:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#     entities = state.state_vals[\"ents\"]\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#     legal_positions = heist.get_legal_mouse_positions(full_grid, entities)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m state_vals \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_vals\u001b[49m\n\u001b[1;32m     42\u001b[0m lock_positions_after \u001b[38;5;241m=\u001b[39m heist\u001b[38;5;241m.\u001b[39mget_lock_statuses(state_vals)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# print(lock_positions_before, lock_positions_after)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# if lock_positions_before != lock_positions_after:\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#     num_changes_counted +=1\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# lock_positions_before = lock_positions_after\u001b[39;00m\n",
      "File \u001b[0;32m~/werk/ai-safety-camp-2024-model-agents/notebooks/heist.py:312\u001b[0m, in \u001b[0;36mEnvState.state_vals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstate_vals\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_maze_state_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/werk/ai-safety-camp-2024-model-agents/notebooks/heist.py:538\u001b[0m, in \u001b[0;36m_parse_maze_state_bytes\u001b[0;34m(state_bytes, assert_)\u001b[0m\n\u001b[1;32m    536\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val_def \u001b[38;5;129;01min\u001b[39;00m HEIST_STATE_DICT_TEMPLATE:\n\u001b[0;32m--> 538\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43mparse_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m assert_:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    543\u001b[0m         _serialize_maze_state(vals, assert_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m state_bytes\n\u001b[1;32m    544\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialize(deserialize(state_bytes)) != state_bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/werk/ai-safety-camp-2024-model-agents/notebooks/heist.py:528\u001b[0m, in \u001b[0;36m_parse_maze_state_bytes.<locals>.parse_value\u001b[0;34m(vals, val_def, idx)\u001b[0m\n\u001b[1;32m    526\u001b[0m         vals_this \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m loop_val_def \u001b[38;5;129;01min\u001b[39;00m loop_val_defs:\n\u001b[0;32m--> 528\u001b[0m             idx \u001b[38;5;241m=\u001b[39m \u001b[43mparse_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_val_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m         vals[name]\u001b[38;5;241m.\u001b[39mappend(vals_this)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m idx\n",
      "File \u001b[0;32m~/werk/ai-safety-camp-2024-model-agents/notebooks/heist.py:515\u001b[0m, in \u001b[0;36m_parse_maze_state_bytes.<locals>.parse_value\u001b[0;34m(vals, val_def, idx)\u001b[0m\n\u001b[1;32m    513\u001b[0m     vals[name] \u001b[38;5;241m=\u001b[39m StateValue(val, idx)\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 515\u001b[0m     val, idx \u001b[38;5;241m=\u001b[39m \u001b[43mread_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     vals[name] \u001b[38;5;241m=\u001b[39m StateValue(val, idx)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/werk/ai-safety-camp-2024-model-agents/notebooks/heist.py:498\u001b[0m, in \u001b[0;36m_parse_maze_state_bytes.<locals>.<lambda>\u001b[0;34m(sb, idx)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val, idx\n\u001b[1;32m    497\u001b[0m read_int \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m sb, idx: read_fixed(sb, idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@i\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 498\u001b[0m read_float \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m sb, idx: \u001b[43mread_fixed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m@f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_string\u001b[39m(sb, idx):\n\u001b[1;32m    501\u001b[0m     sz, idx \u001b[38;5;241m=\u001b[39m read_int(sb, idx)\n",
      "File \u001b[0;32m~/werk/ai-safety-camp-2024-model-agents/notebooks/heist.py:493\u001b[0m, in \u001b[0;36m_parse_maze_state_bytes.<locals>.read_fixed\u001b[0;34m(sb, idx, fmt)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_fixed\u001b[39m(sb, idx, fmt):\n\u001b[1;32m    492\u001b[0m     sz \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mcalcsize(fmt)\n\u001b[0;32m--> 493\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msb\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    494\u001b[0m     idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sz\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val, idx\n",
      "\u001b[0;31merror\u001b[0m: unpack requires a buffer of 4 bytes"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"../model_9501.0.pt\"\n",
    "\n",
    "model = helpers.load_model(model_path=model_path)\n",
    "layer_number = 14\n",
    "start_level = random.randint(1, 10000)\n",
    "save_gif = False\n",
    "episode_timeout = 200\n",
    "num_levels=1\n",
    "venv = heist.create_venv(num=1, num_levels=num_levels, start_level=start_level)\n",
    "\n",
    "start_level = random.randint(1, 10000)\n",
    "venv = heist.create_venv(num=1, num_levels=num_levels, start_level=start_level)\n",
    "state = heist.state_from_venv(venv, 0)\n",
    "unchanged_obs = venv.reset()\n",
    "\n",
    "\n",
    "\n",
    "unchanged_obs= venv.reset()\n",
    "state_values = state.state_vals\n",
    "\n",
    "for ents in state_values[\"ents\"]:\n",
    "    if ents[\"image_type\"].val== 9:\n",
    "        gem_x = ents[\"x\"].val \n",
    "        gem_y = ents[\"y\"].val \n",
    "\n",
    "state.remove_gem()\n",
    "\n",
    "\n",
    "state_bytes = state.state_bytes\n",
    "if state_bytes is not None:\n",
    "    venv.env.callmethod(\"set_state\", [state_bytes])\n",
    "    modified_obs = venv.reset()\n",
    "\n",
    "state = heist.state_from_venv(venv, 0)\n",
    "\n",
    "state.set_gem_position(gem_y-.5,gem_x-.5)\n",
    "\n",
    "state_bytes = state.state_bytes\n",
    "\n",
    "if state_bytes is not None:\n",
    "    venv.env.callmethod(\"set_state\", [state_bytes])\n",
    "# Load model and calculate steering vector\n",
    "model = helpers.load_model(model_path=model_path)\n",
    "layer_names = helpers.get_model_layer_names(model)\n",
    "steering_layer_unchanged = ordered_layer_names[layer_number]\n",
    "steering_layer = helpers.rename_path(steering_layer_unchanged)\n",
    "\n",
    "model_activations = helpers.ModelActivations(model)\n",
    "model_activations.clear_hooks()\n",
    "output1, unmodified_activations = model_activations.run_with_cache(helpers.observation_to_rgb(unchanged_obs), layer_names)\n",
    "model_activations.clear_hooks()\n",
    "output2, modified_obs_activations = model_activations.run_with_cache(helpers.observation_to_rgb(modified_obs), layer_names)\n",
    "\n",
    "steering_vector = unmodified_activations[steering_layer][0] - modified_obs_activations[steering_layer][0]\n",
    "\n",
    "run_episode_with_steering_and_check_target_acquisition(\n",
    "        venv, model, steering_vector, steering_layer=ordered_layer_names[layer_number],\n",
    "        modification_value=modification_value, filepath=f'episode_steering_locks.gif',\n",
    "        save_gif=False, episode_timeout=episode_timeout\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_positions_before = helpers.get_lock_positions(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lock_positions_after' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlock_positions_after\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lock_positions_after' is not defined"
     ]
    }
   ],
   "source": [
    "lock_positions_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classified_dataset = heist.create_classified_dataset(num_samples_per_category=900, num_levels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-safety-camp-Y8XZewIj-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
