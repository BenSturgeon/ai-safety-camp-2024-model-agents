{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heist\n",
    "import helpers\n",
    "import torch.distributions\n",
    "import torch\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from helpers import generate_action, load_model\n",
    "from procgen import ProcgenGym3Env\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import typing\n",
    "import math\n",
    "\n",
    "from procgen import ProcgenGym3Env\n",
    "import struct\n",
    "import typing\n",
    "from typing import Tuple, Dict, Callable, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from src.policies_modified import ImpalaCNN\n",
    "from procgen_tools.procgen_wrappers import VecExtractDictObs, TransposeFrame, ScaledFloatFrame\n",
    "\n",
    "from gym3 import ToBaselinesVecEnv\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ordered_layer_names = {\n",
    " 0: 'conv_seqs',\n",
    " 1: 'conv_seqs.0',\n",
    " 2: 'conv_seqs.0.conv',\n",
    " 3: 'conv_seqs.0.max_pool2d',\n",
    " 4: 'conv_seqs.0.res_block0',\n",
    " 5: 'conv_seqs.0.res_block0.conv0',\n",
    " 6: 'conv_seqs.0.res_block0.conv1',\n",
    " 7: 'conv_seqs.0.res_block1',\n",
    " 8: 'conv_seqs.0.res_block1.conv0',\n",
    " 9: 'conv_seqs.0.res_block1.conv1',\n",
    " 10: 'conv_seqs.1',\n",
    " 11: 'conv_seqs.1.conv',\n",
    " 12: 'conv_seqs.1.max_pool2d',\n",
    " 13: 'conv_seqs.1.res_block0',\n",
    " 14: 'conv_seqs.1.res_block0.conv0',\n",
    " 15: 'conv_seqs.1.res_block0.conv1',\n",
    " 16: 'conv_seqs.1.res_block1',\n",
    " 17: 'conv_seqs.1.res_block1.conv0',\n",
    " 18: 'conv_seqs.1.res_block1.conv1',\n",
    " 19: 'conv_seqs.2',\n",
    " 20: 'conv_seqs.2.conv',\n",
    " 21: 'conv_seqs.2.max_pool2d',\n",
    " 22: 'conv_seqs.2.res_block0',\n",
    " 23: 'conv_seqs.2.res_block0.conv0',\n",
    " 24: 'conv_seqs.2.res_block0.conv1',\n",
    " 25: 'conv_seqs.2.res_block1',\n",
    " 26: 'conv_seqs.2.res_block1.conv0',\n",
    " 27: 'conv_seqs.2.res_block1.conv1',\n",
    " 28: 'hidden_fc',\n",
    " 29: 'logits_fc',\n",
    " 30: 'value_fc'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gem_steering_experiment(model_path, layer_number, modification_value, num_levels=1, start_level=5, episode_timeout=200, save_gif=False):\n",
    "    start_level = random.randint(1, 10000)\n",
    "    venv = heist.create_venv(num=1, num_levels=num_levels, start_level=start_level)\n",
    "    state = heist.state_from_venv(venv, 0)\n",
    "    unchanged_obs = venv.reset()\n",
    "\n",
    "\n",
    "\n",
    "    unchanged_obs= venv.reset()\n",
    "    state_values = state.state_vals\n",
    "\n",
    "    for ents in state_values[\"ents\"]:\n",
    "        if ents[\"image_type\"].val== 9:\n",
    "            gem_x = ents[\"x\"].val \n",
    "            gem_y = ents[\"y\"].val \n",
    "\n",
    "    state.remove_gem()\n",
    "\n",
    "\n",
    "    state_bytes = state.state_bytes\n",
    "    if state_bytes is not None:\n",
    "        venv.env.callmethod(\"set_state\", [state_bytes])\n",
    "        modified_obs = venv.reset()\n",
    "\n",
    "    state = heist.state_from_venv(venv, 0)\n",
    "\n",
    "    state.set_gem_position(gem_y-.5,gem_x-.5)\n",
    "\n",
    "    state_bytes = state.state_bytes\n",
    "\n",
    "    if state_bytes is not None:\n",
    "        venv.env.callmethod(\"set_state\", [state_bytes])\n",
    "    # Load model and calculate steering vector\n",
    "    model = helpers.load_model(model_path=model_path)\n",
    "    layer_names = helpers.get_model_layer_names(model)\n",
    "    steering_layer_unchanged = ordered_layer_names[layer_number]\n",
    "    steering_layer = helpers.rename_path(steering_layer_unchanged)\n",
    "\n",
    "    model_activations = helpers.ModelActivations(model)\n",
    "    model_activations.clear_hooks()\n",
    "    output1, unmodified_activations = model_activations.run_with_cache(helpers.observation_to_rgb(unchanged_obs), layer_names)\n",
    "    model_activations.clear_hooks()\n",
    "    output2, modified_obs_activations = model_activations.run_with_cache(helpers.observation_to_rgb(modified_obs), layer_names)\n",
    "\n",
    "    steering_vector = unmodified_activations[steering_layer][0] - modified_obs_activations[steering_layer][0]\n",
    "\n",
    "\n",
    "    # Run episode with steering\n",
    "    total_reward_steering, frames_steering, observations_steering = helpers.run_episode_with_steering_and_save_as_gif(\n",
    "        venv, model, steering_vector, steering_layer=ordered_layer_names[layer_number],\n",
    "        modification_value=modification_value, filepath=f'episode_steering_{episode}.gif',\n",
    "        save_gif=save_gif, episode_timeout=episode_timeout\n",
    "    )\n",
    "\n",
    "    return total_reward_steering, total_reward\n",
    "\n",
    "\n",
    "model_path = \"../model_9501.0.pt\"\n",
    "modification_value = -2\n",
    "total_episodes = 20\n",
    "best_layer = None\n",
    "best_score = 0\n",
    "\n",
    "for layer_number in range(1, 30):  # Adjusted range to be between 1 and 29 inclusive\n",
    "    count_rewards_0 = 0\n",
    "    for episode in range(total_episodes):\n",
    "        filepath=f'episode_steering_{episode}.gif'\n",
    "        total_reward_steering, total_reward = run_gem_steering_experiment(model_path, layer_number, modification_value, save_gif=False, filepath=filepath)\n",
    "        if total_reward_steering == 0:\n",
    "            count_rewards_0 += 1\n",
    "    print(f\"Layer {ordered_layer_names[layer_number]}, {layer_number}: Number of times total reward steering was 0: {count_rewards_0}/{total_episodes}\")\n",
    "    if count_rewards_0 > best_score:\n",
    "        best_score = count_rewards_0\n",
    "        best_layer = layer_number\n",
    "\n",
    "print(f\"Best layer: {best_layer} with score: {best_score}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-safety-camp-Y8XZewIj-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
